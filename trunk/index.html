<!DOCTYPE html>
<!--
CUDA squeeze web site
(C) 2013, Benjamin Hugo, Heinrich Strauss & Brandon Talbot
-->
<html>
<head>
<title>CUDA Squeeze</title>
<link rel="stylesheet" type="text/css" href="css/default.css">
<script type="text/javascript" src="js/tabCode.js"></script>
</head>

<body onload="initTabs()">
<div id="titleBar">
	<table id="projecttitle">
		<tbody>
			<tr>
				<td id="cslogoCol">
					<a id="logolink" href="http://www.cs.uct.ac.za/"><img id="cslogo" src="img/uctcs.square.logo.png"/></a>
				</td>
				<td id="logoCol">
					<img id="logo" src="img/logo.png"/>
				</td>
				<td id="skalogoCol">
					<a class="logolink" href="http://www.ska.ac.za/"><img id="skalogo" src="img/ska.square.logo.png"/></a>
				</td>
			</tr>
		</tbody>
	</table>
</div>
<div class="sideBlank"> <br/></div><div class="mainDiv">
<!--Define the tabs-->
<ul id="tabs">
  <li><a href="#synopsis">Project Synopsis</a></li>
  <li><a href="#supervision">Supervision</a></li>
  <li><a href="#timeline">Timeline</a></li>
  <li><a href="#benCorner">Benjamin's Corner</a></li>
  <li><a href="#brandonCorner">Brandon's Corner</a></li>
  <li><a href="#straussCorner">Strauss' Corner</a></li>
  <li><a href="#links">Links and Downloads</a></li>
  
</ul>
<!--Define tab pages-->
<div class="tabContent" id="synopsis">
  <h1 class="indivHeading1">About CUDA Squeeze</h2>
  <div>
    <!--  <p class="TODO">TODO: WRITE STUFF HERE CHECK ANNE'S ANNOUNCEMENT</p>
    <p class="instructions">Your project Web pages contain material relevant to the project as a whole and to your individual
contribution to the project. The Web site must be self-contained with relative links only. Web sites
must be completely static -- this means no PHP, ASP, server-side JS or any such scripts. If your
project is a web-accessible application, you must add an absolute link from the project Web site to
the Web application, labelling it as a non-permanent external link. Please be sparing with external
links and only link to well-established sites that are likely to remain for a long time.
The entry point to the project is the project (group) Web page. This must indicate the
accomplishments of the project and have the documents produced jointly by the team (like the project proposal). 
In future this will be the first impression people get of the work you did for your honours project. 
The main entry page must be called index.html and must be located in the root directory
of the website</p><p class="instructions">
Individual Web sites are a statement of the work of the individual. A mark is assigned for this
when the Web pages are evaluated. All supporting documentation must be part of each Web site.
Document files must be in a portable format (e.g., PDF, HTML), with Microsoft Word and LaTeX
files converted as needed. Source code should be linked into Web pages as compressed archives.</p> -->
<p class="basicText">The SKA (Square Kilometer Array) South Africa requires a compression algorithm that offers reasonable compression ratios, as well as being fast enough to keep up with the antenna output rates. 
This need arises due
to the requirement of saving streaming data onto a storage system and reading queries from that system
simultaneously. This is where the focus of our project lies. We will be taking streaming data from correlators
and beamformers (which combines pairs of data channels from the antennae) and compress the data-stream
using optimised CPU (with SSE and AVX) and GPGPU (General-Purpose Computing on Graphical Processing Units) implementations in order to achieve the speeds
that SKA requires, while maintaining reasonable compression ratios. We operate as a 'shim' between the Compute Nodes and the storage sub-system.</p>
  </div>
</div>
<div class="tabContent" id="supervision">
  <h1 class="indivHeading1">About our supervisors</h2>
  <div>   <!--  <p class="TODO">TODO: WRITE STUFF HERE ABOUT JAMES, PATRICK AND JASON</p> -->
    <h3 class="supervisorTitle">Associate-Professor James Gain</h3>
    <p class="basicText">Professor James Gain completed his Masters at Rhodes University with distinction in 1995. After two years of teaching, he moved on to complete his Doctorate at Cambridge University.</p>
    <p class="basicText">He has been a Senior Lecturer at the University of Cape Town since 2000 and was promoted to Associate-Professor in December 2009.</p>
    <h3 class="supervisorTitle">Doctor Patrick Marais</h3>
    <p class="basicText">Doctor Patrick Marais completed his Masters in Computer Science at the University of Cape Town in 1994 and his Doctorate in Engineering Science at Oxford University in 1997.</p>
    <p class="basicText">He currently occupies a Senior Lecturer post at the University of Cape Town and is a member of the Collaborative Visual Computing (CVC) and High-Performance Computing (HPC) laboratories.</p> 
    <h3 class="supervisorTitle">Jason Manley (external advisor)</h3>
    <p class="basicText">Jason Manley is a Digital Design Engineer and Digital Signal Processing specialist at the SKA office in Pinelands.</p>
    <p class="basicText">Jason has provided valuable insight into the SKA architecture and serves as our external advisor.</p>
    
  </div>
</div><div class="tabContent" id="timeline">
  <h1 class="indivHeading1">Project Timeline</h2>
  <div>
     <img class="timeline" src="img/ganttchart.png"/>
 
  </div>
</div>
<div class="tabContent" id="benCorner">
 <h1 class="indivHeading1">Algorithm - Predictive Compression</h1>
 <p>As we stated in the synopsis our goal is to develop 3 algorithms for compressing the 32 bit floating point radio astronomy data
	  of the Square Kilometer Array (SKA). Although each of the group members are investigating a particular compression scheme, our goal is
	  to publish our findings jointly in order to establish which of the 3 schemes performs best in terms of the tradeoff between throughput 
	  and compression ratio.</p>
	  <p>I will be investigating a predictive compression scheme. In such a scheme the streaming data is divided into chunks which can be
	  processed in parallel. The goal is to divide the data in such a way as to exploit dimensional coherency (lets say compressing the values
	  of a particular frequency over several time steps). Since the values will likely not change much (or change relatively slowly over the
	  duration of several steps) the prediction scheme may yield accurate predictions of consequtive values. If this is the case the difference
	  between both mantisa bits and exponent bits of the predicted value and the actual value will result in many leading zero bits, which can 
	  be stored in compressed form (saving the residual bits in uncompressed form). Such a scheme is simple and fast (see my paper litterature survey)
	  and is ideal for scenarios where throughput enjoys preference over good compression ratios.</p>
	  <p>I will be implementing both an optimised CPU version (using both a vectorised instruction set when ever possible, as well as being
	  multithreaded) and a GPU version of the code if time permits.</p>
</div>
<div class="tabContent" id="brandonCorner">
 <h1 class="indivHeading1">Algorithm - Huffman Coding</h1>
 <p>
 	Huffman coding is a Entropy Coding algorithm, which compresses files by replacing all values in the file with shorter representations of them.
 	<br>
 	It calculates what to represent each value as by giving each unique value in the file a shorter representation, giving those values that apear the most in the file shorter representations. 
 	This give it a better compression than just randomly giving each unique value a new representation, since one that apears the most could have a larger representation given to it than one that only apears once.
 	<br>
 	It saves the file by placing a table with a table showing what each value was changed to, and then the stream of replaced values.
 	<br>
 	<br>
 	This algorithm can be done for streaming data by making a small adjustment. Each new value that is read is placed into a list which shows each unique value, and how many times that value has been seen so far. 
 	At each stage it then calculates the new values (if needed) and continues using the new value, making note of the change. It can then decompress the file since it knows the change took place, and when.
 	<br>
 	<br>
 	Three versions of the algorithm are to be made:
 </p>
 <ul>
 	<li>Sequential CPU - Normal Adaptive Huffman Coding algorithm</li>
 	<li>Fully Multi-threaded CPU - Complient to SSE and AVX-Enabled CPU version of the Adaptive Huffman coding algorithm</li>
 	<li>GPU - A GPU implementation of the Adaptive Huffman Coding algorithm</li>
 </ul>
 <p>
 	Tests will then be done to see if it is capapble of meeting SKAs requirements, and if the CUDA inplementation is even worth the effort.
 </p>
</div>
<div class="tabContent" id="straussCorner">
 <!--     <h2>Strauss's section</h2> -->
  <div>
    <!--     <iframe class="individualpages" src="import/strauss.html"/> -->
    <h1 class="indivHeading1">Algorithm - Zero-Length Encoding</h1>
    <p class="basicText">The third implemented algorithm will be Zero-Length Encoding, a derivative of Run-Length Encoding, which I will investigate.</p>
    <p class="basicText">Zero-Length Encoding is basically run-length encoding, just performed on the binary representation of data.
In Zero-Length Encoding you run through the data and replace sections of the binary stream where there are
multiple 0s or 1s with the number of repetitions and what is repeating, Eg. 1000001 becomes 1(5)01. where
the (5) is a tag to say it is a number representation and the 5 to tell how many 0s there are.
This is a viable option because the data samples we receive are skewed towards the least-significant bits.
</p>
<p class="basicText">This algorithm should be tweaked to efficiently handle the various patterns the data will follow, which are dependent on the number of dishes in use for a particular observation and the spectrum being captured.</p>
    <p class="basicText">Again, a SSE- and AVX-enabled CPU version will be done, followed by a GPU-optimised implementation.</p>
    <p class="basicText">This allows for a cohesive comparison of the different methods, excluding Arithmetic Coding which was shown in practice (by our supervisors, et al.) to provide insufficient throughput for our purposes in 2012.</p>
    <!-- <p>Blank</p> -->
  </div>
</div>
<div class="tabContent" id="links">
 <!--     <h2>Strauss's section</h2> -->
  <div>
    <!--     <iframe class="individualpages" src="import/strauss.html"/> -->
    <h1 class="indivHeading1">Project Resources</h1>
   <ul>
    <li class="incompleteLink"><a class="linkDownload" href="res/cuda-squeeze-proposal.pdf" target="_blank">Project Proposal</a></li>
    <li class="incompleteLink"><!-- <a class="linkDownload" href="http://people.cs.uct.ac.za/~patrick/">Doctor Patrick Marais (external)</a> -->Project Source</li>
    </ul>
   
<h1 class="indivHeading1">Supervisors:</h1><ul>
    <li><a class="extSupervisor" href="http://people.cs.uct.ac.za/~jgain/" target="_blank">Associate-Professor James Gain (UCT)</a></li>
    <li><a class="extSupervisor" href="http://people.cs.uct.ac.za/~patrick/" target="_blank">Doctor Patrick Marais (UCT)</a></li>
    <li><a class="extSupervisor" href="http://www.ska.ac.za/" target="_blank">SKA South Africa (external)</a></li>
    </ul>
    <h1 class="indivHeading1">Team Members:</h1><ul>
    <li><a class="linkMemberPages" href="http://people.cs.uct.ac.za/~bhugo/"    target="_blank">Benjamin Hugo (UCT)</a></li>
    <li><a class="linkMemberPages" href="http://people.cs.uct.ac.za/~btalbot/"  target="_blank">Brandon Talbot (UCT)</a></li>
    <li><a class="linkMemberPages" href="http://people.cs.uct.ac.za/~hstrauss/" target="_blank">Heinrich Strauss (UCT)</a></li>
    </ul>
    <h1 class="indivHeading1">Acknowledgements:</h1><p class="acknowledgement">The financial assistance of the National Research Foundation (NRF) towards this research is hereby acknowledged. Opinions expressed and conclusions arrived at, are those of the author and are not necessarily to be attributed to the NRF.</p>
  </div>
</div>
</div><div class="sideBlank"><br/></div>

</body>

</html> 
